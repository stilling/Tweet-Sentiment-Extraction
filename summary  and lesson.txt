       为了完成课程作业，我最近组队参加了第一次kaggle的比赛，Tweet Sentiment Extraction(Extract support phrases for sentiment labels)，最后幸运的取得了一枚银牌，得分0.7189(56/2227,Top 2.5%)。
在这次比赛中，个人虽然没发挥什么实质性的贡献，全靠队友给力。但对利用深度学习技术解决nlp任务和模型优化中的trick都有了更深的了解和体会，最后对这次比赛做一个学习和分享。
一、赛题要求
       本次赛题来自于Twitter的现实场景，我们需要从给定的每条推特文本text和对应的情绪'positive'、'negative'或是'neutral'中提取反应情绪的那一部分文本。
       例如对于给定的文本“My blackberry is soon approaching her death”和情感“negative”中，找到反应情绪的文本“death”。
       
       

二、解决方案
1.编码形式
       我们可以把这个任务理解为一个QA问答问题(Question-Answering)，将情感标签（积极、消极、中性）抽象为问答问题中的问题（Question），将抽取文本当作问答问题中答案（Answer）。
       在词向量的建立中，我们将情绪标签加入到text的句尾， 将token embedding设计为<s>text</s></s>sentiment</s>。然后使用one hot编码的形式表示selected text在原始text文本中的起始和终止位置。
       ![Image](https://github.com/stilling/image-store/blob/master/embedding.png)

2.模型构建
       在实现中，建立了一个12层的RoBERTa模型，RoBERTa模型的输出是输入各字对应的融合全文语义信息后的向量表示。对于RoBERTa模型的输出，我们使用两个1*1的卷积核去从输出中提取情感文本的起始和终止位置。
     （1）模型的数据输入。TweetDataset类。将输入数据转换为模型dataset的输入格式.
       即将tweet、sentiment、selected_text的数据转换为ids（<s>sentiment</s></s><token_tweet_ids></s>对应的token_ids）, token_type（ids的类型）,mask（0/1表示对应位置是否需要遮掩）,
       tweet_offsets(对应字符在原始文本中的起始位置和终止位置)，然后用padding填充到max_len返回。
       
      （2）模型的建立。roberta的三元组输出(最后一层的隐变量，最后一层第一个token的隐变量，最后一层的隐变量或每一层attentions 权重参数)，将out输出的768*2的向量通过nn.Linear转换为二维向量，分别对应预测结果的起始和终止位置。
      （3）模型训练。使用k-折交叉验证，将数据加载入dataset中训练模型。使用交叉熵损失函数，衡量情感文本起始位置和结束位置在预测集和测试集中的差距。
       模型使用pytorch框架，利用GPU进行训练。将情感标签和推特原文进行拼接，利用Tokenizer获得输入文本的ids和mask，进而输入模型得到情感文本的起始和结束的预测，而后与真实标注文本的起始位置和终止位置计算误差进行反向传播参数更新，再利用jaccard相似度计算预测文本和真实标注文本的相似度。
       定义的batch_size为32，max_len为96，并加入了带随机数的十折交叉验证，定义学习率为0.005的Adam优化器进行模型训练。

      （4）模型评估。在engine.py中定义了损失函数、训练函数和评估函数。利用jaccard相似度评估结果。
三、优化trick
1.预处理和后处理
RoBERTa仅为此创建一个令牌"..."，因此您的模型无法选择"fun."文本是否为"This is fun..."。因此，在预处理期间，将所有单个[...]标记转换为三个[.][.][.]标记。同样，拆分"..", "!!", "!!!"。

2.标签平滑
目的：为了避免让模型过度的相信标签值，学习到噪音数据，造成过拟合，我们使用了标签平滑技术。
方法：标签平滑主要改进是在one-hot部分，原本one-hot只有在真正的起始位置或终止位置对应标签值为1，其它值为0。而标签平滑则是在真正的起始位置或终止位置对应标签值为1-ε ，其余各个位置平分平滑值ε。
但是由于在训练过程中我们将每一个batch的数据填充到同样的长度，但是对于填充的位置(<pad>)其参与平分平滑值显然是不合理的。所以我们加以改进，实现了带掩码的标签平滑，带掩码的标签平滑会忽略调填充的位置。


3.对抗训练
对抗训练原理就是通过添加扰动构造一些对抗样本，让模型去训练，模型在扰动样本上进行训练，就可以提升对于扰动的抵御能力提升对于对抗样本的鲁棒性，同时一定程度上提高模型的表现和泛化能力。
对抗训练的公式为：min┬???〖??_((??,??)) 〗~??[max┬(???∈??)?〖??(??+???,??;??)]〗
其中公式整体分为两个部分，一个是内部损失函数最大化，一个是外部经验风险最小化。内部max是为了找到最有效的攻击，对模型造成扰动，使模型出错。外部的min是为了基于该攻击方式，找到最佳鲁棒性的参数进行抵御扰动的干扰。

4.预处理
（1）拆分标点。由于Roberta模型的token中将...和.看作是一种类型的token，我们将所有的连续的标点符号都用空格拆分。
（2）去除多余空格。利用' '.join(text.spilt())获得无多余空格的纯净文本，再将两者中情感文本的起始位置相减，得到多余的额外空格。